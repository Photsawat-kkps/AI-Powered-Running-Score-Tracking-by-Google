# Sports Day Reinvented: AIâ€‘Powered Running Score Tracking by Google

> **Who is this for?**
> - **Nonâ€‘technical readers**: See how we turned messy photos into clean, trustworthy running results.
> - **Technical readers**: Dive into the data flow, parsing rules, and code snippets (with links to deepâ€‘dives).
>
> **How to read**
> - The **Main Story** runs from **1 â†’ 5**.
> - Sidebars marked **(Deepâ€‘dive)** can be skimmed now and read later.
> - Look for **ðŸ–¼ï¸ Image here** to know where to drop screenshots/diagrams.

---

## 1) Project Overview (Main Story)
**Goal:** Automate runningâ€‘result collection on Sports Dayâ€”**from photos â†’ structured data â†’ verified results**â€”to reduce manual tallying, speed up publishing, and cut human errors.

- **Problem**: Results were captured as phone photos (scoreboards, watch screens, treadmill panels). Manual typing was slow, errorâ€‘prone, and hard to audit.
- **Solution**: Use **Google Cloud Vision** to read text (OCR), then apply **domainâ€‘specific parsing rules** to extract **time (HH:MM:SS)** and **distance (km)** reliably, autoâ€‘validate, and export to a results sheet/dashboard.
- **Outcome**: Faster result turnaround, traceable errors, consistent scoringâ€”**with human oversight minimized to exceptions**.

ðŸ–¼ï¸ **Image here:** A before/after collage (raw scoreboard photo â†’ highlighted OCR text â†’ clean table of results)

**Key highlights**
- Images â†’ Vision API â†’ text lines â†’ smart parser (time vs. pace vs. random numbers) â†’ **validated rows**
- Outdoor vs. Indoor flows handled (watch photo vs. treadmill panel)
- Automatic anomaly checks (e.g., impossible distance/time, mixed punctuation â€œ01.13.52â€)

> **Deepâ€‘dive references**: [Appendix A. Parsing Rules](#appendix-a-parsing-rules-cheat-sheet), [Appendix B. Data Validation](#appendix-b-data-validation--error-handling)

---

## 2) What We OCR (Contexts & Inputs) (Main Story)
**Event Context:** School/office **Sports Day** with **running events** (e.g., 100m, 5km fun run, relay). Data sources include:

- **Scoreboards** (handwritten/printed; photos from phones)
- **Watch screenshots** (Garmin/Apple/Android) showing **elapsed time** and **distance**
- **Treadmill panels** (Indoor) showing **time, distance, pace**

**Input artifacts**
- Photo uploads via **Google Form** â†’ saved in **Google Drive**
- Form metadata (team, runner ID, outdoor/indoor, optional notes) â†’ **Google Sheet** (`Form Responses 1`)

ðŸ–¼ï¸ **Image here:** Example scoreboard photo + watch screenshot + treadmill panel (3â€‘up grid)

> **Deepâ€‘dive:** [Appendix C. Sample Dataset & Annotations](#appendix-c-sample-dataset--annotations)

---

## 3) Tech Stack (Quick) (Main Story)
- **Cloud OCR**: **Google Cloud Vision API** (Text Detection)
- **Compute**: Python 3.11 (local or Cloud Run/Functions)
- **Data**: Google Sheets (working tab + output tab), pandas for transforms
- **Automation (optional)**: Cloud Scheduler â†’ trigger runner; Cloud Storage for images
- **Auth/Access**: Service Account (JSON key or Workload Identity)
- **Logging**: Python logging (JSON), optional export to a dashboard

```
# Minimal client stub (Python)
from google.cloud import vision

client = vision.ImageAnnotatorClient()
response = client.text_detection(image=vision.Image(content=img_bytes))
text = response.full_text_annotation.text
```

> **Deepâ€‘dive:** [Appendix D. Setup & Deployment](#appendix-d-setup--deployment)

---

## 4) Pipeline (Endâ€‘toâ€‘End) (Main Story)

**At a glance**
```
Phone Photo â†’ Google Form â†’ Google Drive
                  â†“
            Form Responses (Sheet)
                  â†“  (trigger)
           OCR Worker (Python)
                  â†“
         Vision API â†’ text blocks
                  â†“
  Smart Parser (time, km, pace; rules)
                  â†“
     Validation & Anomaly detection
                  â†“
  Working Sheet  â†’  Results Sheet/Dashboard
```

ðŸ–¼ï¸ **Image here:** Clean architecture diagram (boxes/arrows). Keep this near the top for nonâ€‘tech readers.

**Detailed steps**
1. **Ingest**: New form rows detected (or batch backfill for empty results).
2. **Fetch media**: Download photo from Drive; preprocess (resize, grayscale if needed).
3. **OCR**: Vision API â†’ full text + perâ€‘block coordinates (if needed later).
4. **Parsing**:
   - Prefer real **time patterns** `HH:MM:SS` or `MM:SS`.
   - Accept `MM:SS.ff` (e.g., `04:53.79`) as **valid time**; map `.ff` to fractional seconds.
   - Resolve **mixed punctuation**: `01.13.52` / `01.13:52` â†’ normalize to `01:13:52` only if unambiguous.
   - **Distance candidates**: decimals in **2.0â€“35.0 km** (configurable) to filter out calories/randoms.
   - **Anchor logic**: if a clear distance is found near keywords (â€œkmâ€, â€œdistanceâ€), remaining timeâ€‘like tokens are treated as **time**, not pace.
   - Avoid false dates like `23.09.2025` when extracting time.
5. **Validation**: crossâ€‘check timeâ†”distance ranges (e.g., 2 km cannot have 2 hours), indoor vs. outdoor heuristics.
6. **Writeâ€‘back**: Structured row â†’ **Working Sheet** (with flags) â†’ **Results Sheet**.
7. **Notify (optional)**: Slack/Email for anomalies or low OCR confidence.

> **Deepâ€‘dives**: [Appendix A](#appendix-a-parsing-rules-cheat-sheet), [Appendix B](#appendix-b-data-validation--error-handling)

---

## 5) Results (Main Story)
**What improved?**
- **Turnaround time**: Faster publishing (no manual retyping)
- **Accuracy**: Domain rules eliminate common OCR slips (e.g., pace mistaken as time)
- **Auditability**: Every row links back to the original image + parser decision
- **Scalability**: Add more devices/photos without adding staff

ðŸ–¼ï¸ **Image here:**
- **Before/After table**: Left = raw OCR text; Right = final columns (Time, Distance, Validity, Event, Team)
- **Dashboard snapshot**: Topline stats (finishers, avg pace, fastest times) per color/team

**Example output columns**
- `Timestamp` (from form)
- `Runner ID`, `Team`
- `Event Type` (Outdoor/Indoor)
- `Time_HHMMSS`, `Distance_km`
- `Validation_Status` (`OK / Different / N/A`)
- `Notes` (auto or reviewer)

> **Deepâ€‘dive**: [Appendix E. Result Schema](#appendix-e-result-schema)

---

## (Optional) 6) Why This Works (For Both Audiences)
- **For organizers**: Less chaos on event day, faster announcements, fewer disputes.
- **For engineers**: Domainâ€‘aware parsing + layered validation beats generic OCR for numeric panels/scoreboards.

---

## (Optional) 7) Limitations & Next Steps
**Known limits**
- Blurry/angled photos, reflective panels, overlapped digits
- Mixed language UIs; unusual fonts
- Edge cases: split screens with multiple times; longâ€‘run times > 2h with tiny text

**Next steps**
- Add **AutoML / custom prompts** for scoreboard layouts
- Confidence scoring + humanâ€‘inâ€‘theâ€‘loop review UI
- **Privacy**: face blurring for public reports; consent checklist

---

## (Optional) 8) Quickstart (Tech)
> Keep this short in README; link to the appendix for detailed steps.

1) **Prereqs**
- Python 3.11, `pip install -r requirements.txt`
- Google Cloud project + Vision API enabled
- Service account key available

2) **Run locally**
```
export GOOGLE_APPLICATION_CREDENTIALS=path/to/key.json
python ocr_runner.py --sheet "Form Responses 1" --out "Working"
```

3) **Deploy (oneâ€‘liner idea)**
- Cloud Run/Functions with scheduler trigger; see [Appendix D](#appendix-d-setup--deployment)

---

# Appendices (Deepâ€‘dives)

## Appendix A. Parsing Rules (Cheat Sheet)
- **Time**
  - Prefer strict `HH:MM:SS` or `MM:SS`
  - Accept `MM:SS.ff` (e.g., `04:53.79`) â†’ treat `.ff` as fractional seconds
  - Reject likely **dates** (e.g., `23.09.2025`)
  - Normalize mixed separators: `01.13.52` â†’ `01:13:52` only if context supports
- **Distance (km)**
  - Accept decimals **2.0â€“35.0** (tunable)
  - Favor tokens near `km`, `KM`, `Distance`, or typical device labels
- **Anchor precedence**
  - If a plausible distance is anchored, remaining timeâ€‘like tokens â†’ **time** (not pace)
- **Indoor vs. Outdoor**
  - Indoor: prefer treadmillâ€™s panel values (time, distance) when present
  - Outdoor: prefer watch elapsed time; avoid misreading pace `MM:SS /km` as time

## Appendix B. Data Validation & Error Handling
- **Consistency checks**
  - Unlikely pairs flagged (e.g., 2.0 km with 02:00:00 â†’ `Different`)
  - Missing either time or distance â†’ `N/A`
- **Confidence**
  - Low OCR confidence or conflicting tokens â†’ require review
- **Logging**
  - JSON logs (`timestamp`, `runner_id`, `decision`, `reason`) for traceability

## Appendix C. Sample Dataset & Annotations
- Curate a small set (10â€“20 images): scoreboard, watch, treadmill
- Provide: original image, OCR text dump, parser decision, validation status
- **ðŸ–¼ï¸ Image grid here** with short captions

## Appendix D. Setup & Deployment
- Enable Vision API; create service account
- Grant Drive/Sheets read/write scopes (if using gspread/Google API client)
- Environment vars: credentials path, sheet names, image bucket/folder
- (Optional) Cloud Run/Functions template and scheduler cron

## Appendix E. Result Schema
| Column | Type | Notes |
|---|---|---|
| Timestamp | datetime | From Google Form |
| Runner ID | string | From form |
| Team | string | e.g., Blue / Green |
| Event Type | enum | Outdoor / Indoor |
| Time_HHMMSS | string | Normalized time |
| Distance_km | float | 2.00â€“35.00 |
| Validation_Status | enum | OK / Different / N/A |
| Notes | string | Parser comment or reviewer |

---

## Credits & Ethics
- Built with **Google Cloud Vision** (preâ€‘trained AI for text detection)
- Respect **privacy**: obtain consent; blur faces before public sharing
- Acknowledge volunteers who submitted images and helped label edge cases

---

### Visual Placement Guide (Quick)
- **Top of README**: Before/after collage (hook nonâ€‘tech readers)
- **Section 4**: Architecture diagram (one clear graphic)
- **Section 5**: Table snapshot + dashboard screenshot
- **Appendix C**: Multiâ€‘image grid with captions

> Keep the main story brisk. Push regexes, full code, and cost/quotas to the **appendices** to keep momentum for mixed audiences.

